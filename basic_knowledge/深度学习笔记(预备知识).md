# 深度学习介绍
课程首先讲了一些应用
- 图片分类
- 物体检测和分割
- 样式迁移
- 人脸合成
- 文生图
- 文字生成（LLM）
- 无人驾驶（特斯拉的FSD）
- 案例：广告点击
	1. 触发
	2. 点击率预估（通过模型）
	3. 排序

# 安装环境
### 使用 conda/miniconda 环境
```bash
conda env remove d2l-zh
conda create -n d2l-zh python=3.9 pip -y
conda activate d2l-zh
```

### 安装需要的包
```bash
pip install jupyter d2l torch torchvision -i https://pypi.tuna.tsinghua.edu.cn/simple
```
> **注意：这是一行哦，BTW，代理没关有概率不行，关掉再试哦**

### 下载代码并执行
```bash
wget https://zh-v2.d2l.ai/d2l-zh.zip
unzip d2l-zh.zip
jupyter notebook
```

# 数据操作
### N维数组样例
***N维数组是机器学习和神经网络的主要数据结构***
我把3-d、4-d、5-d数组的内容补充到之前的表格里，让N维数组的示例更完整：

| 维度类型    | 示例图形                             | 数据形式                                                                                                                          | 含义                     |
| ------- | -------------------------------- | ----------------------------------------------------------------------------------------------------------------------------- | ---------------------- |
| 0-d（标量） | ■                                | 1.0                                                                                                                           | 一个类别                   |
| 1-d（向量） | ▬▬▬▬                             | [1.0, 2.7, 3.4]                                                                                                               | 一个特征向量                 |
| 2-d（矩阵） | □□□<br>□□□<br>□□□                | \[\[1.0, 2.7, 3.4]<br>\[5.0, 0.2, 4.6]<br>\[4.3, 8.5, 0.2]]                                                                   | 一个样本—特征矩阵              |
| 3-d     | 🧊（立方体）                          | \[\[\[0.1, 2.7, 3.4]<br>\[5.0, 0.2, 4.6]<br>\[4.3, 8.5, 0.2]]<br>\[\[3.2, 5.7, 3.4]<br>\[5.4, 6.2, 3.2]<br>\[4.1, 3.5, 6.2]]] | RGB图片（宽x高x通道）          |
| 4-d     | 🧊🧊🧊🧊                         | \[\[\[\[.  .   .]]]]                                                                                                          | 一个RGB图片批量（批量大小x宽x高x通道） |
| 5-d     | 🧊🧊🧊🧊<br>🧊🧊🧊🧊<br>🧊🧊🧊🧊 | \[\[\[\[\[.  .  .]]]]]                                                                                                        | 一个视频批量（批量大小x时间x宽x高x通道） |
### 创建数组
创建数组需要指定以下核心要素：
- **形状**：例如 `3×4` 矩阵
- **每个元素的数据类型**：例如32位浮点数
- **每个元素的值**：例如全是0、全是1，或随机数（如正态分布、均匀分布）

### 访问元素
在N维数组（以二维矩阵为例）中，可通过**索引/切片**精准访问元素，以下是常见操作及说明（注：原“一列”的索引写法有误，正确写法应为 `[:,1]`）：
![[Pasted image 20260201191426.png]]

| 访问类型    | 索引写法          | 效果说明                                               | 示例（基于4×4矩阵）                                                                                                                 |
| ------- | ------------- | -------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| 单个元素    | `[行索引, 列索引]`  | 定位矩阵中某一个元素（索引从0开始）                                 | `[1,2]` → 选中第2行、第3列的元素 `7`                                                                                                  |
| 整行      | `[行索引, :]`    | 选中某一行的所有元素（`:` 表示“所有”）                             | `[1,:]` → 选中第2行 `[5,6,7,8]`                                                                                                 |
| 整列      | `[:, 列索引]`    | 选中某一列的所有元素（原图中 `[1,:]` 是错误写法，正确为 `[:,1]`）          | `[:,1]` → 选中第2列 `[2,6,10,14]`                                                                                               |
| 子区域（切片） | `[行切片, 列切片]`  | 通过“起始索引:结束索引”（左闭右开）选中连续区域                          | `[1:3, 1:]` → 选中第2-3行、第2列及之后的区域；                                                                                            |
| 间隔切片    | `[::步长,::步长]` | 通过 `::步长` 按指定间隔选元素（`::3` 表示 “从第 0 个开始，每 3 个选 1 个”） | `[::3,::2]` → 行：每 3 行选 1 行（选第 1 行 `[0]` 、第 4 行 `[3]`）；列：每 2 列选 1 列（选第 1 列 `[0]`、第 3 列 `[2]`）→ 最终选中 `[1,3]` 和 `[13,15]` 两个元素 |

### 核心规则
- 索引从 **0** 开始（行/列的第一个元素索引是0）；
- 切片用 `a:b` 表示：包含索引`a`，不包含索引`b`；
- `:` 单独使用表示“选中所有行/列”。
- `::n` 表示 “以 n 为步长，从头到尾间隔选取元素”；

# 数据操作实现
### 入门
- 张量表示一个由数值组成的数组，这个数组可能有多个维度。 具有一个轴的张量对应数学上的_向量_（vector）； 具有两个轴的张量对应数学上的_矩阵_（matrix）； 具有两个轴以上的张量没有特殊的数学名称。
- 可以使用 `arange` 创建一个行向量 `x`。它们默认创建为整数。也可指定创建类型为浮点数。张量中的每个值都称为张量的 _元素_（element）。
```python
import torch

x = torch.arange(12)
print(x)
```

```
tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
```
- 可以通过张量的`shape`属性来访问张量（沿每个轴的长度）的 _形状_ 。
```python
print(x.shape)
```

```
torch.Size([12])
```
>**如果只想知道张量中元素的总数，即形状的所有元素乘积，可以检查它的大小（size）。 因为这里在处理的是一个向量，所以它的`shape`与它的`size`相同。**

```python
print(x.numel())
```

```
12
```
- 调用`reshape`函数。 可以改变张量的形状，但不改变其元素值。 
```python
x = x.reshape(3,4)
print(x)
```

```
tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
```
> 可以自动计算，使用`x.reshape(-1,4)`或`x.reshape(3,-1)`

- 我们可以创建一个形状为（2,3,4）的张量，其中所有元素都设置为0。
```python
print(torch.zeros((2,3,4)))
```

```
tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])
```
> 同理可以用`torch.ones((2,3,4))`创建全1的张量

- 也可以使用`randn()`得到随机值
```python
print(torch.randn(3,4))
```

```
tensor([[ 1.2693,  0.5354,  0.2139, -0.1880],
        [-0.3535,  0.8924,  0.0058, -2.2594],
        [ 0.5834, -1.1979, -1.9191,  1.2037]])
```

- 当然也可以用列表为每个元素赋值
```python
print(torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]))
```

```
tensor([[2, 1, 4, 3],
        [1, 2, 3, 4],
        [4, 3, 2, 1]])
```

### 运算符
- 按元素运算
```python
import torch

x = torch.tensor([1.0,2,4,8])
y = torch.tensor([2,2,2,2])

print(f"{x+y},\n{x-y},\n{x*y},\n{x/y},\n{x**y}")
```

```
tensor([ 3.,  4.,  6., 10.]),
tensor([-1.,  0.,  2.,  6.]),
tensor([ 2.,  4.,  8., 16.]),
tensor([0.5000, 1.0000, 2.0000, 4.0000]),
tensor([ 1.,  4., 16., 64.])
```

- 还包括求幂
```python
print(torch.exp(x))
```
>**`exp()`是$exp(x_i​)=e^{x_i}$​

```
tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])
```

```python
# 不指定dtype时，默认生成64位整数
X = torch.arange(12, dtype=torch.float32).reshape((3,4))
Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
print(torch.cat((X, Y), dim=0))
print(torch.cat((X, Y), dim=1))
```
- `dim`参数是连结哪个轴的，0是张量形状的第一个元素是行，以下同理
```
tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  5.,  6.,  7.],
        [ 8.,  9., 10., 11.],
        [ 2.,  1.,  4.,  3.],
        [ 1.,  2.,  3.,  4.],
        [ 4.,  3.,  2.,  1.]])
tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],
        [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],
        [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]])
```
- 通过 _逻辑运算符_ 构建二元张量。
```python
print(X == Y)
```

```
tensor([[False,  True, False,  True],
        [False, False, False, False],
        [False, False, False, False]])
```
- 求和
```python
print(X.sum())
```

```
tensor(66.)
```

### 广播机制
 在某些情况下，即使形状不同，我们仍然可以通过调用 _广播机制_（broadcasting mechanism）来执行按元素操作。 这种机制的工作方式如下：

1. 通过适当复制元素来扩展一个或两个数组，以便在转换之后，两个张量具有相同的形状；
2. 对生成的数组执行按元素操作。
> 维数应该相同

```python
a = torch.arange(3).reshape((3, 1))
b = torch.arange(2).reshape((1, 2))
print(a+b)
```

```
tensor([[0, 1],
        [1, 2],
        [2, 3]])
```

### 节省内存
- 虽然Python没有C/C++复杂的内存管理，但是节省内存仍然是有必要的
- 可以先看一个例子
```python
before = id(Y)
Y = Y + X
print(id(Y) == before)
```

```
False
```

```python
Z = torch.zeros_like(Y)
print('id(Z):', id(Z))
Z[:] = X + Y
print('id(Z):', id(Z))
```

```
id(Z): 2377502158336
id(Z): 2377502158336
```

- 当然不复制，直接`X += Y`是可以的
### 转换到其他Python对象
```python
A = X.numpy()
B = torch.tensor(A)
print(type(A), type(B))
```

```python
a = torch.tensor([3.5])
print(a, a.item(), float(a), int(a))
```

# 数据预处理
### 读取数据集
- 创建一个人工数据集，并存储在CSV（逗号分隔值）文件
> CSV（Comma-Separated Values，逗号分隔值）是一种**轻量级文本格式**，用于存储表格数据（行×列结构）

```python
import os

os.makedirs(os.path.join('..', 'data'), exist_ok=True)
data_file = os.path.join('..', 'data', 'house_tiny.csv')
with open(data_file, 'w') as f:
    f.write('NumRooms,Alley,Price\n')  # 列名
    f.write('NA,Pave,127500\n')  # 每行表示一个数据样本
    f.write('2,NA,106000\n')
    f.write('4,NA,178100\n')
    f.write('NA,NA,140000\n')
```
- 要从创建的CSV文件中加载原始数据集，我们导入pandas包并调用read_csv函数。

```python
import pandas as pd
data = pd.read_csv(data_file)
print(data)
```

```
0       NaN  Pave  127500
1       2.0   NaN  106000
2       4.0   NaN  178100
3       NaN   NaN  140000
```

### 处理缺失数据

- “NaN”项代表缺失值。 为了处理缺失的数据，典型的方法包括_插值法_和_删除法_， 其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值。 在这里，我们将考虑插值法。

```python
inputs, outputs = data.iloc[:, 1], data.iloc[:, 1]
numeric_cols = inputs.select_dtypes(include=['number']).columns
inputs[numeric_cols] = inputs[numeric_cols].fillna(inputs[numeric_cols].mean())
print(inputs)
```

```
   NumRooms Alley
0       3.0  Pave
1       2.0   NaN
2       4.0   NaN
3       3.0   NaN
```

- 这是一段**Pandas**数据处理代码，常用于机器学习/数据分析的**特征值与标签值拆分**和**缺失值填充**
#### 1. `inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]`
核心语法：`iloc` 是Pandas**按位置索引**选取数据的方法，格式：`iloc[行索引, 列索引]`
- `:` ：表示**选取所有行**
- `0:2` ：表示选取**第0列、第1列**（左闭右开规则，不包含索引2），赋值给 `inputs`（模型输入/特征数据）
- `2` ：表示选取**第2列**，赋值给 `outputs`（模型输出/标签数据）

**简单理解**：把表格的前两列作为输入特征，第三列作为目标输出，完成数据集拆分。

---

#### 2. `inputs[numeric_cols] = inputs[numeric_cols].fillna(inputs[numeric_cols].mean())`
处理表格中常见的**缺失值（NaN/空值）**：
- `fillna()`：Pandas填充缺失值的函数，括号内为填充用的数值
- `inputs.mean()`：计算`inputs`中**每一列各自的平均值**
- 整体作用：用**每一列的均值**，替换该列中所有的空值/缺失值，保证数据完整，避免后续建模/计算报错

1. **适用场景**：这是数据分析、机器学习预处理的标准操作，解决数据缺失问题，拆分特征与标签；
2. **左闭右开规则**：`0:2` 只取索引0、1，是Python切片的通用规则；
3. **均值填充特点**：适用于**数值型数据**（整数/浮点数），文本数据不能用此方法填充。

- 我们将“NaN”视为一个类别。 由于“巷子类型”（“Alley”）列只接受两种类型的类别值“Pave”和“NaN”， `pandas`可以自动将此列转换为两列“Alley_Pave”和“Alley_nan”。

```python
inputs = pd.get_dummies(inputs, dummy_na=True)
print(inputs)
```

```
   NumRooms  Alley_Pave  Alley_nan
0       3.0        True      False
1       2.0       False       True
2       4.0       False       True
3       3.0       False       True
```

> **可以在`dummy_na=True`后面加上`dtype=int`**

```
   NumRooms  Alley_Pave  Alley_nan
0       3.0           1          0
1       2.0           0          1
2       4.0           0          1
3       3.0           0          1
```

那么同时，此时再运行前面的原始代码也就可以了

```python
inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]
inputs = inputs.fillna(inputs.mean())
print(inputs)
```

>**起码不会报错`TypeError`**

### 转换为张量形式

```python
import torch

X = torch.tensor(inputs.to_numpy(dtype=float))
y = torch.tensor(outputs.to_numpy(dtype=float))
print(X, y)
```

